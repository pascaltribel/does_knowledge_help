{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf21215-7109-47e5-a612-5b79327c56cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: trying to import DISCO convolutions without optional dependency torch-harmonics.  Please install with `pip install torch-harmonics` and retry.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "from utils import rnmse\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from torch.utils.data import Subset\n",
    "from neuralop import FNO\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('notebook')\n",
    "sns.set_palette('hot', n_colors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67469d70-0107-4b9a-a090-91731baa9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.cat([torch.load(\"dataset/x_train.pt\"), torch.load(\"dataset/x_train_2.pt\")])\n",
    "y = torch.cat([torch.load(\"dataset/y_train.pt\"), torch.load(\"dataset/y_train_2.pt\")])\n",
    "c = torch.cat([torch.load(\"dataset/c_train.pt\"), torch.load(\"dataset/c_train_2.pt\")])\n",
    "\n",
    "x_test = torch.load(\"dataset/x_test.pt\")\n",
    "y_test = torch.load(\"dataset/y_test.pt\")\n",
    "c_test = torch.load(\"dataset/c_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0815a670-1755-4dc4-b5ff-aaf529adb81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0, c0 = x[0], y[0], c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "524a9819-6aec-4229-9a8e-18869d981761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 128]) torch.Size([256, 128]) torch.Size([128, 128])\n"
     ]
    }
   ],
   "source": [
    "print(x0.shape, y0.shape, c0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07200bd-0f24-4ea7-9d82-f2456284a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PermuteLayer(torch.nn.Module):\n",
    "    dims: tuple[int, ...]\n",
    "\n",
    "    def __init__(self, dims: tuple[int, ...]) -> None:\n",
    "        super().__init__()\n",
    "        self.dims = dims\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return input.permute(*self.dims)\n",
    "        \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net_x = nn.Sequential(\n",
    "            nn.Linear(x0.shape[-1], 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            PermuteLayer((0, 2, 1)),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            PermuteLayer((0, 2, 1)),\n",
    "        )\n",
    "        self.net_c = nn.Sequential(\n",
    "            nn.Linear(c0.shape[-1], 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.net_y = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, y0.shape[-1])\n",
    "        )\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        return self.net_y(torch.concatenate([self.net_x(x), self.net_c(c)], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ff0c49e-ba38-4900-ab14-2734c5be90eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer_rnmse(estimator, x, y):\n",
    "    return rnmse(estimator.predict(x), y)\n",
    "\n",
    "def get_rnmse():\n",
    "    return rnmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "286825cf-b056-4b16-9d75-8f3a7aebcb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'\n",
    "n_points = x.shape[0]\n",
    "n_epochs = 8\n",
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9745004-d2ca-4f6a-9d7b-a07050beb7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 128\n",
    "\n",
    "x_np, y_np, c_np = x.numpy(), y.numpy(), c.numpy()\n",
    "x_np_reshaped, y_np_reshaped, c_np_reshaped = x_np.reshape((x_np.shape[0], -1)), y_np.reshape((y_np.shape[0], -1)), c_np.reshape((c_np.shape[0], -1))\n",
    "x_test_np, y_test_np, c_test_np = x_test.numpy(), y_test.numpy(), c_test.numpy()\n",
    "x_test_np_reshaped, y_test_np_reshaped, c_test_np_reshaped = x_test_np.reshape((x_test_np.shape[0], -1)), y_test_np.reshape((y_test_np.shape[0], -1)), c_test_np.reshape((c_test_np.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fca57fce-1f8d-417d-9409-80ea7bc69478",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MLP, TRAIN_CNN, TRAIN_FNO = True, True, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2033369-7de3-45be-8ed6-559bf8fdc865",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lm = TransformedTargetRegressor(\n",
    "    regressor=Pipeline([\n",
    "        (\"pca\", PCA(n_components=n_components)),\n",
    "        (\"lm\", LinearRegression(n_jobs=-1))\n",
    "    ]),\n",
    "    transformer=PCA(n_components=n_components),\n",
    "    check_inverse=False\n",
    ")\n",
    "\n",
    "scores[\"LM\"] = cross_val_score(\n",
    "    pipe_lm,\n",
    "    x_np_reshaped[:n_points], y_np_reshaped[:n_points],\n",
    "    cv=5,\n",
    "    scoring=scorer_rnmse\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bff61219-15d1-4210-9d4f-168ffc5082dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70db83cb888f4ac499c61902ecbb90cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0907175757668235]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7169516d8c304563a11664a8f3ff96bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0907175757668235, 0.0894691131331704]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6d9377f7e347aa9a92713b0e93300d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0907175757668235, 0.0894691131331704, 0.09016042947769165]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2f586e5c1b4722bd0f0a9ae44037ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0907175757668235, 0.0894691131331704, 0.09016042947769165, 0.09002359346909956]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc48b08c5f145a3a6a643ec9f79ea88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0907175757668235, 0.0894691131331704, 0.09016042947769165, 0.09002359346909956, 0.09196593544699928]\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_MLP:\n",
    "    train = TensorDataset(x[:n_points].to(device), c[:n_points].to(device), y[:n_points].to(device))\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    val_losses = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(train)):\n",
    "        train_subset = DataLoader(Subset(train, train_idx), batch_size=32, shuffle=True)\n",
    "        val_subset = DataLoader(Subset(train, val_idx), batch_size=256, shuffle=True)\n",
    "        pipe_lm = TransformedTargetRegressor(\n",
    "            regressor=Pipeline([\n",
    "                (\"pca\", PCA(n_components=512)),\n",
    "                (\"lm\", LinearRegression(n_jobs=-1))\n",
    "            ]),\n",
    "            transformer=PCA(n_components=512),\n",
    "            check_inverse=False\n",
    "        )\n",
    "        train_x_np = []\n",
    "        train_y_np = []\n",
    "        for x_batch, c_batch, y_batch in train_subset:\n",
    "            train_x_np.append(x_batch.cpu().detach().numpy().reshape(x_batch.shape[0], -1))\n",
    "            train_y_np.append(y_batch.cpu().detach().numpy().reshape(y_batch.shape[0], -1))\n",
    "        pipe_lm.fit(np.concatenate(train_x_np, axis=0), np.concatenate(train_y_np, axis=0))\n",
    "        model = MLP().to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "        loss_fn = rnmse\n",
    "        model.train()\n",
    "        for _ in (pbar:=tqdm(range(n_epochs))):\n",
    "            for x_batch, c_batch, y_batch in train_subset:\n",
    "                optimizer.zero_grad()\n",
    "                lm_pred = torch.tensor(pipe_lm.predict(x_batch.cpu().detach().numpy().reshape(x_batch.shape[0], -1))).to(device).reshape(x_batch.shape)\n",
    "                y_hat = lm_pred + model(x_batch, c_batch)\n",
    "                loss = loss_fn(y_hat, y_batch)\n",
    "                loss.backward()\n",
    "                pbar.set_description(f\"Loss: {loss.item():.5f}\")\n",
    "                optimizer.step()\n",
    "        model.eval()\n",
    "        loss_val = 0\n",
    "        for x_batch, c_batch, y_batch in val_subset:\n",
    "            lm_pred = torch.tensor(pipe_lm.predict(x_batch.cpu().detach().numpy().reshape(x_batch.shape[0], -1))).to(device).reshape(x_batch.shape)\n",
    "            y_hat = lm_pred + model(x_batch, c_batch)\n",
    "            loss_val += loss_fn(y_hat, y_batch)\n",
    "        val_losses.append(loss_val.item()/len(val_subset))\n",
    "        print(val_losses)\n",
    "    \n",
    "    scores[\"MLP\"] = val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2396247-37ac-4f5c-aba1-df16f85e7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net_x = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, padding=\"same\"),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(4, 8, kernel_size=3, padding=\"same\"),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d((2, 1)),\n",
    "        )\n",
    "        self.net_c = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, padding=\"same\"),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(4, 8, kernel_size=3, padding=\"same\"),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.net_y = nn.Sequential(\n",
    "            nn.Conv2d(16, 8, kernel_size=3, padding=\"same\"),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(8, 1, kernel_size=3, padding=\"same\"),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose2d(1, 1, kernel_size=(2, 1), stride=(2, 1))\n",
    "        )\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        x, c = x.unsqueeze(1), c.unsqueeze(1)\n",
    "        return self.net_y(torch.concatenate([self.net_x(x), self.net_c(c)], axis=1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af744fa9-4d62-4f6b-bd03-20164bd61b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if TRAIN_CNN:\n",
    "    train = TensorDataset(x[:n_points].to(device), c[:n_points].to(device), y[:n_points].to(device))\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    val_losses = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(train)):\n",
    "        train_subset = DataLoader(Subset(train, train_idx), batch_size=32, shuffle=True)\n",
    "        val_subset = DataLoader(Subset(train, val_idx), batch_size=32, shuffle=True)\n",
    "        pipe_lm = TransformedTargetRegressor(\n",
    "            regressor=Pipeline([\n",
    "                (\"pca\", PCA(n_components=512)),\n",
    "                (\"lm\", LinearRegression(n_jobs=-1))\n",
    "            ]),\n",
    "            transformer=PCA(n_components=512),\n",
    "            check_inverse=False\n",
    "        )\n",
    "        train_x_np = []\n",
    "        train_y_np = []\n",
    "        for x_batch, c_batch, y_batch in train_subset:\n",
    "            train_x_np.append(x_batch.cpu().detach().numpy().reshape(x_batch.shape[0], -1))\n",
    "            train_y_np.append(y_batch.cpu().detach().numpy().reshape(y_batch.shape[0], -1))\n",
    "        pipe_lm.fit(np.concatenate(train_x_np, axis=0), np.concatenate(train_y_np, axis=0))\n",
    "        model = CNN().to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "        loss_fn = rnmse\n",
    "        model.train()\n",
    "        for _ in (pbar:=tqdm(range(n_epochs))):\n",
    "            for x_batch, c_batch, y_batch in train_subset:\n",
    "                optimizer.zero_grad()\n",
    "                lm_pred = torch.tensor(pipe_lm.predict(x_batch.cpu().detach().numpy().reshape(x_batch.shape[0], -1))).to(device).reshape(x_batch.shape)\n",
    "                y_hat = lm_pred + model(x_batch, c_batch)\n",
    "                loss = loss_fn(y_hat, y_batch)\n",
    "                loss.backward()\n",
    "                pbar.set_description(f\"Loss: {loss.item():.5f}\")\n",
    "                optimizer.step()\n",
    "        model.eval()\n",
    "        loss_val = 0\n",
    "        for x_batch, c_batch, y_batch in val_subset:\n",
    "            lm_pred = torch.tensor(pipe_lm.predict(x_batch.cpu().detach().numpy().reshape(x_batch.shape[0], -1))).to(device).reshape(x_batch.shape)\n",
    "            y_hat = lm_pred + model(x_batch, c_batch)\n",
    "            loss_val += loss_fn(y_hat, y_batch)\n",
    "        val_losses.append(loss_val.item()/len(val_subset))\n",
    "        print(val_losses)\n",
    "    scores[\"CNN\"] = val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73207d1-4921-4824-9d38-17f9291a7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNOp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net_x = nn.Sequential(\n",
    "            nn.MaxPool2d((2, 1)),\n",
    "        )\n",
    "        self.fno = nn.Sequential(\n",
    "            FNO(n_modes=(16, 16), hidden_channels=16, in_channels=2, out_channels=1),\n",
    "        )\n",
    "        self.tail = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1, 1, kernel_size=(2, 1), stride=(2, 1))\n",
    "        )\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        x, c = x.unsqueeze(1), c.unsqueeze(1)\n",
    "        return self.tail(self.fno(torch.concatenate([self.net_x(x), c], axis=1))).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e88ac-f100-463b-bc38-eedcae7fbcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_FNO:\n",
    "    train = TensorDataset(x[:n_points].to(device), c[:n_points].to(device), y[:n_points].to(device))\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    val_losses = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(train)):\n",
    "        train_subset = DataLoader(Subset(train, train_idx), batch_size=32, shuffle=True)\n",
    "        val_subset = DataLoader(Subset(train, val_idx), batch_size=32, shuffle=True)\n",
    "        pipe_lm = TransformedTargetRegressor(\n",
    "            regressor=Pipeline([\n",
    "                (\"pca\", PCA(n_components=512)),\n",
    "                (\"lm\", LinearRegression(n_jobs=-1))\n",
    "            ]),\n",
    "            transformer=PCA(n_components=512),\n",
    "            check_inverse=False\n",
    "        )\n",
    "        train_x_np = []\n",
    "        train_y_np = []\n",
    "        for x_batch, c_batch, y_batch in train_subset:\n",
    "            train_x_np.append(x_batch.cpu().detach().numpy().reshape(x_batch.shape[0], -1))\n",
    "            train_y_np.append(y_batch.cpu().detach().numpy().reshape(y_batch.shape[0], -1))\n",
    "        pipe_lm.fit(np.concatenate(train_x_np, axis=0), np.concatenate(train_y_np, axis=0))\n",
    "        model = FNOp().to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "        loss_fn = rnmse\n",
    "        model.train()\n",
    "        for _ in (pbar:=tqdm(range(n_epochs))):\n",
    "            for x_batch, c_batch, y_batch in train_subset:\n",
    "                optimizer.zero_grad()\n",
    "                lm_pred = torch.tensor(pipe_lm.predict(x_batch.cpu().detach().numpy().reshape(x_batch.shape[0], -1))).to(device).reshape(x_batch.shape)\n",
    "                y_hat = lm_pred + model(x_batch, c_batch)\n",
    "                loss = loss_fn(y_hat, y_batch)\n",
    "                loss.backward()\n",
    "                pbar.set_description(f\"Loss: {loss.item():.5f}\")\n",
    "                optimizer.step()\n",
    "        model.eval()\n",
    "        loss_val = 0\n",
    "        for x_batch, c_batch, y_batch in val_subset:\n",
    "            lm_pred = torch.tensor(pipe_lm.predict(x_batch.cpu().detach().numpy().reshape(x_batch.shape[0], -1))).to(device).reshape(x_batch.shape)\n",
    "            y_hat = lm_pred + model(x_batch, c_batch)\n",
    "            loss_val += loss_fn(y_hat, y_batch)\n",
    "        val_losses.append(loss_val.item()/len(val_subset))\n",
    "        print(val_losses)\n",
    "    scores[\"FNO\"] = val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f2fb32-626d-4f6a-84d2-1dbbf16fb885",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.boxplot(pd.DataFrame(scores))\n",
    "plt.grid(True)\n",
    "plt.ylabel(\"5-fold CV RNMSE\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(\"5cvrnmse.jpg\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f2f48d-5c81-4243-8eee-bf36f3a94f27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591ae15a-5787-4f81-8ee8-edf042b7a4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded libraries:\n",
      "\t- numpy (np)\n",
      "\t- matplotlib.pyplot (plt)\n",
      "\t- torch\n",
      "\t- torch.nn (nn)\n",
      "\t- torch.optim (optim)\n",
      "\t- tqdm\n"
     ]
    }
   ],
   "source": [
    "%loadlibs\n",
    "from utils import load_datasets, rnmse\n",
    "import torch.fft as fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3f2d59-7a62-4e53-ad70-b647ba02d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx, nt = 128, 256\n",
    "n_epochs = 100\n",
    "l_r = 1e-3\n",
    "dx = 1.0\n",
    "dt = 0.001\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60bd4d4c-fe9b-4c74-8ee4-dc1600ad34c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test, x_min, x_max, c_min, c_max, y_min, y_max = load_datasets(2600, 100, 1000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da2d70c-ac57-47d9-9372-ea6cbf7558c8",
   "metadata": {},
   "source": [
    "Since the acoustic wave equation is given by\n",
    "\n",
    "$$\\frac{\\partial^2 p}{\\partial t^2} = c^2 \\nabla^2 p$$\n",
    "\n",
    "Any NN that respects this equality should play the role of a valid simulator. This means that we can build a NN $\\hat{f}(p_{t-\\delta t}) = \\hat{p}$ that minimizes a loss term\n",
    "\n",
    "$$L = (\\frac{\\partial^2 \\hat{p}}{\\partial t^2} - c^2 \\nabla^2 \\hat{p}-s)^2$$\n",
    "\n",
    "for any input $p_{t-\\delta t}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae39db03-00b3-48d8-837d-a6ed417aadd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(p_t_pdt, p_t_mdt, p, c, s, dx, dt):\n",
    "    p_x_m2dx_y = torch.roll(p, -2, dims=0)\n",
    "    p_x_mdx_y = torch.roll(p, -1, dims=0)\n",
    "    p_x_pdx_y = torch.roll(p, 1, dims=0)\n",
    "    p_x_p2dx_y = torch.roll(p, 2, dims=0)\n",
    "\n",
    "    p_x_y_m2dy = torch.roll(p, -2, dims=1)\n",
    "    p_x_y_mdy = torch.roll(p, -1, dims=1)\n",
    "    p_x_y_pdy = torch.roll(p, 1, dims=1)\n",
    "    p_x_y_p2dy = torch.roll(p, 2, dims=1)\n",
    "    \n",
    "    return ((p_t_pdt - dt**2 * (s + c**2 * (-p_x_m2dx_y + 16*p_x_mdx_y - 60*p + 16*p_x_pdx_y - p_x_p2dx_y \n",
    "                                     - p_x_y_m2dy + 16*p_x_y_mdy + 16*p_x_y_pdy - p_x_y_p2dy)/(12*dx**2)) + p_t_mdt - 2*p)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445bad5-4406-4789-94e0-1a0bd5323e08",
   "metadata": {},
   "source": [
    "And we optimize a simple NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b65e536-7cc0-4d46-a19d-55294ea11f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee449ad2-4e32-4a09-8c3e-8bab845d29ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 128]) torch.Size([64]) torch.Size([64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "from utils import ricker\n",
    "def init(c):\n",
    "    isx = 1\n",
    "    isz = nx // 2\n",
    "    f0  = 15 * 5\n",
    "    dx = 1.0\n",
    "    dt = 0.001\n",
    "    \n",
    "    t = torch.arange(1, nt+1, device=device) * dt\n",
    "    T0 = 1.0 / (15 * 5)\n",
    "\n",
    "    tmp = torch.diff(torch.tensor(ricker(dt, T0), device=device, dtype=torch.float32))*1e2\n",
    "    src = torch.zeros(nt, device=device, dtype=torch.float32)\n",
    "    src[:tmp.numel()] = tmp\n",
    "\n",
    "    lam = c * T0\n",
    "    \n",
    "    x = torch.arange(nx, device=device) * dx\n",
    "    z = x.clone()\n",
    "\n",
    "    sigma = 1.5 * dx\n",
    "    x0, z0 = x[isx], z[isz]\n",
    "\n",
    "    xx = x[:, None]\n",
    "    zz = z[None, :]\n",
    "\n",
    "    sg = torch.exp(-((xx - x0)**2 + (zz - z0)**2) / sigma**2)\n",
    "    sg = sg / sg.max()\n",
    "    return sg, src\n",
    "\n",
    "sg, src = init(torch.ones((nx, nx)))\n",
    "s = (sg.unsqueeze(0) * src.unsqueeze(-1).unsqueeze(-1))\n",
    "print(sg.unsqueeze(0).shape, src.shape, s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0637afe-393d-4d3b-9790-726dbdc866ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralop import FNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "de0ad2a5-3b82-4db8-bab0-d7c6cb7eba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, hidden_channels=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(2, hidden_channels, kernel_size=3, padding=\"same\"),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(hidden_channels, hidden_channels, kernel_size=3, padding=\"same\"),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(hidden_channels, 1, kernel_size=3, padding=\"same\")\n",
    "        )\n",
    "        #self.net2 = nn.Sequential(\n",
    "        #    FNO(n_modes=(32, 32), in_channels=2, out_channels=1, hidden_channels=2),\n",
    "            #nn.Tanh()\n",
    "        #)\n",
    "\n",
    "    def forward(self, u, c, s, dt):\n",
    "        inp = torch.stack([u, c], dim=0).unsqueeze(0)\n",
    "        out = (self.net(inp))\n",
    "        return out[0, 0] + s*dt**2\n",
    "\n",
    "model = PINN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ab57895e-9c20-46fa-803f-2cc8c3d0ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 300*torch.ones((nx, nx)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3406ff28-f2d1-4f88-8934-e4ac69acc0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2226793bca814158a4300ea034b17762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "model.train()\n",
    "n_steps = nt\n",
    "losses = []\n",
    "for epoch in (pbar:=tqdm(range(1000))):\n",
    "    for _ in range(10):\n",
    "        u_prev = torch.randn((nx, nx)).to(device)*1e-6\n",
    "        u = model(u_prev, c, s[0], dt)\n",
    "        loss = 0\n",
    "        opt.zero_grad()\n",
    "        for it in range(1, n_steps):\n",
    "            u_pred = model(u, c, s[it], dt)\n",
    "            loss += loss_fn(u_pred, u_prev, u, c, s[it], dx, dt)\n",
    "            u_prev = u.detach()\n",
    "            u = u_pred.detach()\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        opt.step()\n",
    "        pbar.set_postfix(loss=np.mean(losses[-20:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50946ef5-ba17-4681-aa3d-fa85b371604d",
   "metadata": {},
   "source": [
    "To evaluate the model, we compare its trace with a simple FD one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0036ab2c-c5ad-4bad-8472-8d0fa2aced7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile\n",
    "def fd_step(ap, apold, c, dt, dx, s):\n",
    "    return ap, 2*ap - apold +  dt**2 * (c**2 * (\n",
    "            ((-torch.roll(ap, -2, dims=0) + 16 * torch.roll(ap, -1, dims=0) - 60 * ap + 16 * torch.roll(ap,  1, dims=0) - torch.roll(ap,  2, dims=0) +\n",
    "            (-torch.roll(ap, -2, dims=1) + 16 * torch.roll(ap, -1, dims=1) + 16 * torch.roll(ap,  1, dims=1) - torch.roll(ap,  2, dims=1))) / (12 * dx**2))\n",
    "        ) + s)\n",
    "\n",
    "\n",
    "kx = 2 * torch.pi * torch.fft.fftfreq(nx, d=dx, device=\"mps\")\n",
    "kx2 = -(kx**2).reshape(-1, 1)\n",
    "kz2 = -(kx**2).reshape(1, -1)\n",
    "\n",
    "@torch.compile\n",
    "def spectral_step(sp, spold, c, dt, s):\n",
    "    sp_fft = fft.fft2(sp)\n",
    "    return sp, 2*sp - spold + (c**2 * (fft.ifft2(sp_fft * kx2).real + fft.ifft2(sp_fft * kz2).real) + s) * dt**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13723991-30b0-4b9e-92a5-1e7288d2dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_traces(c, nx, device=\"mps\"):\n",
    "    shape = (nx, nx)\n",
    "    zeros = lambda: torch.zeros(shape, device=device, dtype=torch.float32)\n",
    "\n",
    "    ap    = zeros()\n",
    "    apnew = zeros()\n",
    "    apold = zeros()\n",
    "    ad2px = zeros()\n",
    "    ad2pz = zeros()\n",
    "\n",
    "    trace_ps = []\n",
    "    for it in (range(nt)):\n",
    "        apold, ap = fd_step(ap, apold, c, dt, dx, s[it])\n",
    "        trace_ps.append(ap[0].detach().cpu())\n",
    "    return torch.stack(trace_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4482ec47-8be8-4b2f-9cc0-c26fe4e95d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "t = []\n",
    "u_prev = torch.zeros((nx, nx)).to(device)\n",
    "u = model(u_prev, c, s[0], dt)\n",
    "for it in range(1, n_steps):\n",
    "    u_pred = model(u, c, s[it], dt)\n",
    "    t.append(u_pred[0].clone().cpu().detach())\n",
    "    u_prev = u\n",
    "    u = u_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c6fb2f-c394-4aff-afad-123371f09fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(get_traces(c, nx), aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(torch.stack(t).cpu().detach(), aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e489651-2ded-4926-9f5b-96870f3d79aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec037284-0ae8-44a3-ad4f-c37d59a36679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

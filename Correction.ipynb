{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f62a2d0f-3766-4a96-b70a-f49b2517e904",
   "metadata": {},
   "source": [
    "# Correction Based approach\n",
    "Given a FD solution $\\bar{y}$, the propagation field $c$, predict the PS solution $y$. We try four main approaches:\n",
    "- Given $(\\bar{y}, c)$, design a NN that outputs $\\hat{y} = \\bar{y} + e$\n",
    "- Given $(\\bar{y})$, design a NN that outputs $\\hat{y} = \\bar{y} + e$\n",
    "- Given $(\\bar{y}, c)$, design a NN that outputs $\\hat{y} = f(\\bar{y})$\n",
    "- Given $(\\bar{y})$, design a NN that outputs $\\hat{y} = f(\\bar{y})$\n",
    "\n",
    "The four approaches are tested using train/val/test datasets, on a MLP and a CNN. The loss function is the normalized mean squared error, and the optimizer is AdamW. For fairness, all the architectures are trained on 26000 samples, validated on 1000 and then tested on 1000. Each model is trained for 100 epochs with a fixed learning rate.\n",
    "\n",
    "In the following code, `x` denotes $\\bar{y}$ (the _input_) and $y$ denotes $y$ (the expected _output_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19b72b43-1875-4f8d-9b8a-6b894fc78102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded libraries:\n",
      "\t- numpy (np)\n",
      "\t- matplotlib.pyplot (plt)\n",
      "\t- torch\n",
      "\t- torch.nn (nn)\n",
      "\t- torch.optim (optim)\n",
      "\t- tqdm\n"
     ]
    }
   ],
   "source": [
    "%loadlibs\n",
    "from utils import load_datasets, rnmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4da631c9-88fe-4677-97f9-1ffa4959d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx, nt = 128, 256\n",
    "n_epochs = 10\n",
    "l_r = 5e-5\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c0185bb-a0c1-49cb-9c73-7e9f53c9a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test, x_min, x_max, c_min, c_max, y_min, y_max = load_datasets(26000, 1000, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d2b501-f711-475f-a7fd-6af95f636802",
   "metadata": {},
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32b2218c-e798-4bc6-9fda-e56457e96b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set initial loss: 0.89193\n",
      "Val set initial loss: 0.89092\n",
      "Test set initial loss: 0.89718\n"
     ]
    }
   ],
   "source": [
    "train_loss = 0\n",
    "for xb, cb, yb in train:\n",
    "    xb, cb, yb = xb.to(device), cb.to(device), yb.to(device)\n",
    "    train_loss += rnmse(xb, yb)\n",
    "print(f\"Train set initial loss: {train_loss/len(train):.5f}\")\n",
    "\n",
    "val_loss = 0\n",
    "for xb, cb, yb in val:\n",
    "    xb, cb, yb = xb.to(device), cb.to(device), yb.to(device)\n",
    "    val_loss += rnmse(xb, yb)\n",
    "print(f\"Val set initial loss: {val_loss/len(val):.5f}\")\n",
    "\n",
    "test_loss = 0\n",
    "for xb, cb, yb in test:\n",
    "    xb, cb, yb = xb.to(device), cb.to(device), yb.to(device)\n",
    "    test_loss += rnmse(xb, yb)\n",
    "print(f\"Test set initial loss: {test_loss/len(test):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27762e86-a12e-4350-b12f-9460998e5edc",
   "metadata": {},
   "source": [
    "## 1. Correction term, using $\\bar{y}$ and $c$\n",
    "The first approach designs a neural network outputing a correction term added to the FD solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1e22e90-f2ca-4d75-ba97-9687e470ea12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e371166b189411984c9badb8abbb536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.37236\n",
      "Validation loss: 0.37308\n",
      "Validation loss: 0.36848\n",
      "Validation loss: 0.36648\n",
      "Validation loss: 0.36276\n",
      "Validation loss: 0.35888\n",
      "Validation loss: 0.35443\n",
      "Validation loss: 0.36026\n",
      "Validation loss: 0.34547\n",
      "Validation loss: 0.36359\n",
      "Test loss: 0.35055\n"
     ]
    }
   ],
   "source": [
    "class CorrectionMLP(nn.Module):\n",
    "    def __init__(self, nx, hidden=64):\n",
    "        super().__init__()\n",
    "        self.c_encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(nx * nx, hidden*2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden*2, hidden),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.xt_block = nn.Sequential(\n",
    "            nn.Linear(nx + hidden, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, hidden*2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden*2, nx),\n",
    "        )\n",
    "        self.correction=nn.Sequential(\n",
    "            nn.Linear(nx, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, nx),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        n, nt, nx = x.shape\n",
    "\n",
    "        c_latent = self.c_encoder(c)\n",
    "        c_latent = c_latent[:, None, :].expand(n, nt, -1)\n",
    "\n",
    "        inp = torch.cat([x, c_latent], dim=-1)\n",
    "        y = self.xt_block(inp)\n",
    "        y = self.correction(y)\n",
    "        return y + x\n",
    "\n",
    "model = CorrectionMLP(128, hidden=256).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=l_r)\n",
    "best_val_loss = 10\n",
    "for epoch in (pbar:=tqdm(range(n_epochs))):\n",
    "    model.train()\n",
    "    for xb, cb, yb in train:\n",
    "        xb, cb, yb = xb.to(device), cb.to(device), yb.to(device)\n",
    "        pred = model(xb, cb)\n",
    "        loss = rnmse(pred, yb)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    for xb, cb, yb in val:\n",
    "        xb, cb, yb = xb.to(device), cb.to(device), yb.to(device)\n",
    "        val_loss += rnmse(model(xb, cb), yb)\n",
    "    print(f\"Validation loss: {val_loss/len(val):.5f}\")\n",
    "    if val_loss/len(val) < best_val_loss:\n",
    "        best_val_loss = val_loss/len(val)\n",
    "        torch.save(model, \"saved_models/correction_mlp.pt\")\n",
    "\n",
    "model = torch.load(\"saved_models/correction_mlp.pt\", weights_only=False)\n",
    "test_loss = 0\n",
    "for xb, cb, yb in test:\n",
    "    xb, cb, yb = xb.to(device), cb.to(device), yb.to(device)\n",
    "    test_loss += rnmse(model(xb, cb), yb)\n",
    "print(f\"Test loss: {test_loss/len(test):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b747136a-df26-412d-a631-2ff2913d4960",
   "metadata": {},
   "source": [
    "We do the same using a simple CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "206e2c7a-c35f-41d5-aa9e-605a89930462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43a5a9b978741a1a656b7cdfc655d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 10.30507\n",
      "Validation loss: 1.55229\n",
      "Validation loss: 1.46175\n",
      "Validation loss: 1.34683\n",
      "Validation loss: 1.21439\n",
      "Validation loss: 1.07467\n",
      "Validation loss: 0.93890\n",
      "Validation loss: 0.81581\n",
      "Validation loss: 0.70908\n",
      "Validation loss: 0.61688\n",
      "Test loss: 0.61846\n"
     ]
    }
   ],
   "source": [
    "class CorrectionCNN(nn.Module):\n",
    "    def __init__(self, nx, hidden=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.c_encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, hidden//4, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(hidden//4, hidden//2, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(hidden//2, hidden, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.c_pool = nn.AdaptiveAvgPool2d(1) \n",
    "        self.xt_block = nn.Sequential(\n",
    "            nn.Conv2d(1 + 1, hidden, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(hidden, hidden//2, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(hidden//2, 1, kernel_size=3, padding=1),\n",
    "        )\n",
    "        self.correction = nn.Sequential(\n",
    "            nn.Conv2d(1, hidden, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(hidden, 1, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        B, nt, nx = x.shape\n",
    "        _, cnx1, cnx2 = c.shape\n",
    "        x_img = x.unsqueeze(1) \n",
    "        c_img = c.unsqueeze(1)\n",
    "        c_latent = self.c_encoder(c_img)\n",
    "        c_latent = self.c_pool(c_latent)\n",
    "        c_latent = c_latent.expand(B, -1, nt, nx)\n",
    "        inp = torch.cat([x_img, c_latent.mean(dim=1, keepdim=True)], dim=1)\n",
    "        y = self.xt_block(inp)\n",
    "        y = self.correction(y)\n",
    "        return y.squeeze(1) + x\n",
    "\n",
    "model = CorrectionCNN(128, hidden=8).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=l_r)\n",
    "best_val_loss = 10\n",
    "for epoch in (pbar:=tqdm(range(n_epochs))):\n",
    "    model.train()\n",
    "    for xb, cb, yb in train:\n",
    "        xb, cb, yb = xb.to(device), cb.to(device), yb.to(device)\n",
    "        pred = model(xb, cb)\n",
    "        loss = nmse(pred, yb)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    for xb, cb, yb in val:\n",
    "        xb, cb, yb = xb.to(device), cb.to(device), yb.to(device)\n",
    "        val_loss += nmse(model(xb, cb), yb)\n",
    "    print(f\"Validation loss: {val_loss/len(val):.5f}\")\n",
    "    if val_loss/len(val) < best_val_loss:\n",
    "        best_val_loss = val_loss/len(val)\n",
    "        torch.save(model, \"saved_models/correction_cnn.pt\")\n",
    "\n",
    "model = torch.load(\"saved_models/correction_cnn.pt\", weights_only=False)\n",
    "test_loss = 0\n",
    "for xb, cb, yb in test:\n",
    "    xb, cb, yb = xb.to(device), cb.to(device), yb.to(device)\n",
    "    test_loss += nmse(model(xb, cb), yb)\n",
    "print(f\"Test loss: {test_loss/len(test):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6293b2-39c8-47c8-ad23-b70a5ea072bd",
   "metadata": {},
   "source": [
    "## 2. Correction term, using $\\bar{y}$\n",
    "The second approach designs a neural network outputing a correction term added to the FD solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4bf3844-72e1-49e6-be8b-a3aa9c3e0a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33a0281558c410685165edad617b874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class CorrectionMLP2(nn.Module):\n",
    "    def __init__(self, nx, hidden=64):\n",
    "        super().__init__()\n",
    "        self.xt_block = nn.Sequential(\n",
    "            nn.Linear(nx, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, hidden//2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden//2, nx),\n",
    "        )\n",
    "        self.correction= nn.Sequential(\n",
    "            nn.Linear(nx, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, nx),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        n, nt, nx = x.shape\n",
    "        y = self.xt_block(x)\n",
    "        y = self.correction(y)\n",
    "        return y + x\n",
    "\n",
    "model = CorrectionMLP2(128, hidden=64).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=l_r)\n",
    "best_val_loss = 10\n",
    "for epoch in (pbar:=tqdm(range(n_epochs))):\n",
    "    model.train()\n",
    "    for xb, _, yb in train:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        pred = model(xb)\n",
    "        loss = nmse(pred, yb)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    for xb, _, yb in val:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        val_loss += nmse(model(xb), yb)\n",
    "    print(f\"Validation loss: {val_loss/len(val):.5f}\")\n",
    "    if val_loss/len(val) < best_val_loss:\n",
    "        best_val_loss = val_loss/len(val)\n",
    "        torch.save(model, \"saved_models/correction_mlp_2.pt\")\n",
    "\n",
    "model = torch.load(\"saved_models/correction_mlp_2.pt\", weights_only=False)\n",
    "test_loss = 0\n",
    "for xb, _, yb in test:\n",
    "    xb, yb = xb.to(device), yb.to(device)\n",
    "    test_loss += nmse(model(xb), yb)\n",
    "print(f\"Test loss: {test_loss/len(test):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a0b2c-87c7-4cb7-9ab9-50b8e0f19663",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrectionCNN2(nn.Module):\n",
    "    def __init__(self, nx, hidden=8):\n",
    "        super().__init__()\n",
    "        self.xt_block = nn.Sequential(\n",
    "            nn.Conv2d(1, hidden, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(hidden, hidden//2, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(hidden//2, 1, kernel_size=3, padding=1),\n",
    "        )\n",
    "        self.correction = nn.Sequential(\n",
    "            nn.Conv2d(1, hidden, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(hidden, 1, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, nt, nx = x.shape\n",
    "        x_img = x.unsqueeze(1) \n",
    "        y = self.xt_block(x_img)\n",
    "        y = self.correction(y)\n",
    "        return y.squeeze(1) + x\n",
    "\n",
    "model = CorrectionCNN2(128, hidden=8).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=l_r)\n",
    "best_val_loss = 10\n",
    "for epoch in (pbar:=tqdm(range(n_epochs))):\n",
    "    model.train()\n",
    "    for xb, _, yb in train:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        pred = model(xb)\n",
    "        loss = nmse(pred, yb)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    for xb, _, yb in val:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        val_loss += nmse(model(xb), yb)\n",
    "    print(f\"Validation loss: {val_loss/len(val):.5f}\")\n",
    "    if val_loss/len(val) < best_val_loss:\n",
    "        best_val_loss = val_loss/len(val)\n",
    "        torch.save(model, \"saved_models/correction_cnn_2.pt\")\n",
    "\n",
    "model = torch.load(\"saved_models/correction_cnn_2.pt\", weights_only=False)\n",
    "test_loss = 0\n",
    "for xb, _, yb in test:\n",
    "    xb, yb = xb.to(device), yb.to(device)\n",
    "    test_loss += nmse(model(xb), yb)\n",
    "print(f\"Test loss: {test_loss/len(test):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ee9ca-1624-479d-b03f-6bc80425bbb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
